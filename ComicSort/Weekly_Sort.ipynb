{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89041d55-8e87-4373-9ae2-8672e661e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "from natsort import natsort_keygen\n",
    "import datetime as dt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Custom\n",
    "from file_manager import File_Manager\n",
    "from df_manager import DF_Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b094a0b6-c45f-4747-9807-7fea1b0f652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PUBLISHER_LIST = ['Abstract Studio',\n",
    "                 'Archaia',\n",
    "                 'Archie Comics',\n",
    "                 'Aspen MLT',\n",
    "                 'Avatar Press',\n",
    "                 'Boom! Studios',\n",
    "                 'Dark Horse Comics',\n",
    "                 'DC Comics',\n",
    "                 'Dynamite Entertainment',\n",
    "                 'IDW Publishing',\n",
    "                 'Image',\n",
    "                 'Marvel',\n",
    "                 'Top Cow',\n",
    "                 'Vertigo',\n",
    "                 'Wildstorm',\n",
    "                 'Zenescope Entertainment']\n",
    "\n",
    "PL_LOWER = [p.lower().replace(\"!\", \"\") for p in PUBLISHER_LIST]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7754d1",
   "metadata": {},
   "source": [
    "# Parse Files in HOME_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea622ee9-f498-4db5-8d52-32d3543ba604",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = \"D:\\-=_Comics_=-\\__New Stuff\"\n",
    "#####################################################################\n",
    "# Get File list from folder to be deleted\n",
    "\n",
    "tree = []\n",
    "\n",
    "# Creates a list of all subfolders that contain files\n",
    "for (path, dirs, files) in os.walk(HOME_PATH, topdown=True):\n",
    "    if 'Thumbs.db' in files:\n",
    "        files.remove('Thumbs.db')\n",
    "        os.remove(f\"{path}\\\\Thumbs.db\")\n",
    "    if 'covers.db' in files:\n",
    "        files.remove('covers.db')\n",
    "        os.remove(f\"{path}\\\\covers.db\")\n",
    "    if len(files) > 0:\n",
    "        tree.append((path,files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e850492b-01d6-49ff-b7d7-488900f635f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of import errors:    0\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# Open comic file  and retrieve metadata\n",
    "# File Check to make sure they are readable and no errors\n",
    "\n",
    "FILE_MANAGER = File_Manager()\n",
    "ERROR_LOG = []\n",
    "\n",
    "total_folders = len(tree)\n",
    "current_folder = 0\n",
    "time_start = time.time()\n",
    "\n",
    "for folder in tree:\n",
    "    directory = folder[0]\n",
    "    files = folder[1]\n",
    "    total_files = len(files)\n",
    "    current_file = 0\n",
    "\n",
    "    for file in files:\n",
    "        time_now = str(dt.timedelta(seconds = (time.time() - time_start)))\n",
    "\n",
    "        print(f\"Progress:  {current_folder}/{total_folders} {(current_folder/total_folders)*100:.2f}%  -  {time_now}\")\n",
    "        print(f\"{directory}  -  {current_file}/{total_files} {(current_file/total_files)*100:.2f}%\")\n",
    "        print(file)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        full_path = f\"{directory}\\{file}\"\n",
    "        # print(full_path)\n",
    "        if file.lower().endswith(\".cbr\") or file.lower().endswith(\".cbz\"):\n",
    "            FILE_MANAGER.parse_file(full_path, file)\n",
    "        else:\n",
    "            print(\"Not CBR/CBZ - \", full_path)\n",
    "\n",
    "        current_file += 1\n",
    "\n",
    "    current_folder += 1\n",
    "\n",
    "FILE_MANAGER.print_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ba76fa-1cdf-4ae0-925f-7ebc62a19ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of dictionaries to pandas dataframe for processing\n",
    "df = pd.DataFrame(FILE_MANAGER.FILE_LIST)\n",
    "# Single Folder Run\n",
    "df.to_csv('file_list.csv')\n",
    "\n",
    "## Import from csv (If working outside home)\n",
    "# Import from last csv instead of reprocessing\n",
    "# df = pd.read_csv('file_list.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f67fd09",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Global Folder Run\n",
    "# df.to_csv('comic_list.csv')\n",
    "# df\n",
    "\n",
    "# df_global['Year'] = df_global['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac009705",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c4e0d25",
   "metadata": {},
   "source": [
    "# Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c067aba-3f4c-4cce-8910-8a6adb706770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================Debug Check=======================\n",
      "Passed - Volumes to int\n",
      "Passed - Numbers to float\n",
      "Passed - Years to int\n",
      "Passed - Months to int\n",
      "Passed - Days to int\n",
      "=======Publisher List=========\n",
      "Big:  ['DC Comics', 'Boom! Studios', 'Marvel', 'Dynamite Entertainment', 'Image']\n",
      "Misc:  ['Vault Comics']\n",
      "========Volume List========\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "df.Series = df.Series.str.strip()\n",
    "# Checking Volume numbers\n",
    "df.Volume.fillna(value=0, inplace=True)\n",
    "# Fixing issue number caveats\n",
    "df['Number'].replace('½', .5, inplace=True)\n",
    "df['Number'].replace('1½', .5, inplace=True)\n",
    "df['Number'].replace('∞', 999, inplace=True)\n",
    "df['Number'].replace('Omega', 1, inplace=True)\n",
    "# Fixes issue numbers like \"10AU\" or \"25.BEY\"\n",
    "df['Number'] = df['Number'].astype(str)\n",
    "for i in range(len(df['Number'])):\n",
    "    n_string = df.iloc[i]['Number']\n",
    "\n",
    "    l_int, l_str = \"\", \"\"\n",
    "    for l in n_string:\n",
    "        if not l.isalpha():\n",
    "            l_int+=l\n",
    "        elif l.isalpha():\n",
    "            l_str+=l\n",
    "    if len(l_str) > 0:\n",
    "        if l_int[-1] == \".\":\n",
    "            l_int += \"1\"\n",
    "        else:\n",
    "            l_int += \".1\"\n",
    "    df.at[i,'Number'] = l_int\n",
    "\n",
    "\n",
    "debug_day = pd.DataFrame\n",
    "debug_year = pd.DataFrame\n",
    "debug_number = pd.DataFrame\n",
    "debug_volume = pd.DataFrame\n",
    "\n",
    "print(\"======================Debug Check=======================\")\n",
    "try:\n",
    "    df['Volume'] = df['Volume'].astype(int)\n",
    "    print(\"Passed - Volumes to int\")\n",
    "except Exception as e:\n",
    "    print(\"Failed - Volumes to int\")\n",
    "    print(\"Volume Error - \", e)\n",
    "\n",
    "try:\n",
    "    df['Number'] = df['Number'].astype(float)\n",
    "    print(\"Passed - Numbers to float\")\n",
    "except Exception as e:\n",
    "    print(\"Failed - Numbers to float\")\n",
    "    print('Number Error - ', e)\n",
    "\n",
    "try:\n",
    "    df['Year'] = df['Year'].astype(int)\n",
    "    print(\"Passed - Years to int\")\n",
    "except Exception as e:\n",
    "    print(\"Failed - Years to int\")\n",
    "    print('Year Error - ', e)\n",
    "\n",
    "try:\n",
    "    df['Month'] = df['Month'].astype(int)\n",
    "    print(\"Passed - Months to int\")\n",
    "except Exception as e:\n",
    "    print(\"Failed - Months to int\")\n",
    "    print('Month Error - ', e)\n",
    "\n",
    "try:\n",
    "    # df['Day'].replace(np.NaN, 1, inplace=True)\n",
    "    df['Day'] = df['Day'].astype(int)\n",
    "    print(\"Passed - Days to int\")\n",
    "except Exception as e:\n",
    "    print(\"Failed - Days to int\")\n",
    "    print('Day Error - ', e)\n",
    "    debug_day = df[df['Day'].isna()]\n",
    "    if not debug_day.empty:\n",
    "        print(\"========Days with NaN values===========\")\n",
    "        for row in debug_day.itertuples():\n",
    "            print(row.Index, row.Series, row.Number, \"  -  \", row.FilePath)\n",
    "\n",
    "# Fixes capitalization errors in publisher names\n",
    "publishers = df.Publisher.unique().tolist()\n",
    "for p in publishers:\n",
    "    p=p.lower().replace(\"!\", \"\")\n",
    "    if p in PL_LOWER:\n",
    "        # find index\n",
    "        p_index = PL_LOWER.index(p)\n",
    "        # replace all occurances in df with index in publisher list\n",
    "        df = df.replace(str(p), str(PUBLISHER_LIST[p_index]))\n",
    "# Fix Publisher Names\n",
    "df['Publisher'].replace(\"/\", '&', regex=True, inplace=True)\n",
    "df['Publisher'].replace(\"BOOM! Studios\", 'Boom! Studios', regex=True, inplace=True)\n",
    "# DC Imprints\n",
    "df['Publisher'].replace('I.W. Publishing', 'DC Comics', inplace=True)\n",
    "# Marvel Imprints\n",
    "df['Publisher'].replace('Marvel Digital Comics Unlimited', 'Marvel', inplace=True)\n",
    "df['Publisher'].replace('Marvel Knights', 'Marvel', inplace=True)\n",
    "df['Publisher'].replace('Max', 'Marvel', inplace=True)\n",
    "df['Publisher'].replace('Max Comics', 'Marvel', inplace=True)\n",
    "df['Publisher'].replace('Timely', 'Marvel', inplace=True)\n",
    "df['Publisher'].replace('Marvel Soleil', 'Marvel', inplace=True)\n",
    "df['Publisher'].replace('Marvel UK', 'Marvel', inplace=True)\n",
    "df['Publisher'].replace('Epic', 'Marvel', inplace=True)\n",
    "df['Publisher'].replace('Scholastic Book Services', 'Marvel', inplace=True)\n",
    "# Image Imprints\n",
    "df['Publisher'].replace('Shadowline', 'Image', inplace=True)\n",
    "df['Publisher'].replace('Skybound', 'Image', inplace=True)\n",
    "publishers = df.Publisher.unique().tolist()\n",
    "pub_big = []\n",
    "pub_misc = []\n",
    "for p in publishers:\n",
    "    if p in PUBLISHER_LIST:\n",
    "        pub_big.append(p)\n",
    "    else:\n",
    "        pub_misc.append(p)\n",
    "print('=======Publisher List=========')\n",
    "print(\"Big: \", [*pub_big])\n",
    "print(\"Misc: \", [*pub_misc])\n",
    "\n",
    "print('========Volume List========')\n",
    "print(df['Volume'].unique().tolist())\n",
    "\n",
    "debug_volume = df[df['Volume'] > 10]\n",
    "if not debug_volume.empty:\n",
    "    print(\"=========Files with problem Volumes=========\")\n",
    "    for row in debug_volume.itertuples():\n",
    "        print(row.FilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a3f4f8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_import = df\n",
    "# Import permanent db and merge with imported for processing\n",
    "df_global = pd.read_csv('comic_list.csv', index_col=0,\n",
    "                        dtype = {'Publisher':str,\n",
    "                                 'Series':str,\n",
    "                                 'Volume':int,\n",
    "                                 'Number':float,\n",
    "                                 'Year':int,\n",
    "                                 'Month':int,\n",
    "                                 'Day':int,\n",
    "                                 'FilePath':str,\n",
    "                                 'NewPath':str})\n",
    "df_global = pd.concat([df_import,df_global], ignore_index = True)\n",
    "df_global.sort_values(\n",
    "    by=['Publisher', 'Series','Volume', 'Number','Year', 'Month', 'Day'],\n",
    "    ascending=[True, True, True, True, True, True,True],\n",
    "    inplace=True,\n",
    "    key=natsort_keygen()\n",
    "    )\n",
    "df_global.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e8ed7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e96a8908",
   "metadata": {},
   "source": [
    "# Debugging Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39077c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c80e67",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_global[df_global.Series.isin(df_import['Series'].unique().tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146560e1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_global[(df_global.Series == \"Justice League of America Annual\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4e3d28e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_global.at[5059, \"FilePath\"] = 'D:\\\\-=_Comics_=-\\\\DC Comics\\\\Action Comics (1938)\\\\Action Comics #467.cbz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "477dcb7e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_global = df_global.drop([2988,2989,2991,2992,2994,2995,2997,2998,3000,3001,3003,3004,3267,3268,3895,3896,3898,3899,3901,3902,3922,3923,3925,3926,12372,12373,23070,23071,24049,24050,30432,30433,34799,34800,34801,34802,34803,34804,34986,34987,34989,34990,35956,35957,38954,38955,38957,38958,46583,46584,47264,47265,55448,55449,55451,55452,55454,55455,57381,57382,59426,59427,63973,63974,63976,63977,63979,63980,65759,65760,65762,65763,71034,71035], axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db5ed83c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC Comics\n"
     ]
    }
   ],
   "source": [
    "number_publishers\n",
    "\n",
    "for p in number_publishers:\n",
    "    if p not in root_dict:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc3e8869",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_global.to_csv('comic_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffd29fe9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95058b9e",
   "metadata": {},
   "source": [
    "# Create Move Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b0f4297",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b06cf6771d448a93db03ed67ec61e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dictionary is for sorting and debugging\n",
    "root_dict = {}\n",
    "total_publishers = df_import.Publisher.unique().tolist()\n",
    "for p in total_publishers:\n",
    "    root_dict[p] = {}\n",
    "\n",
    "title_dict = {}\n",
    "\n",
    "titles=df_import.Series.unique()\n",
    "\n",
    "# For testing\n",
    "# titles = ['Deadpool & The Mercs For Money']\n",
    "\n",
    "for title in tqdm(titles):\n",
    "    # For creating folder names.  Removing special characters\n",
    "    safe_title = title.replace(\":\", \" -\")\n",
    "    safe_title = safe_title.replace('/', '-')\n",
    "    safe_title = safe_title.replace('?', '')\n",
    "    safe_title = safe_title.replace('\"', '')\n",
    "    safe_title = safe_title.replace('*', '')\n",
    "\n",
    "    title_dict[safe_title] = {}\n",
    "\n",
    "    # Filter by series\n",
    "    cond_series = (df_global['Series'] == title)\n",
    "    df_by_series = df_global[cond_series]\n",
    "\n",
    "    # Creates list of unique publishers\n",
    "    number_publishers = df_by_series.Publisher.unique().tolist()\n",
    "    # catch for series with same name, multiple publishers.\n",
    "    for p in number_publishers:\n",
    "        if p not in root_dict:\n",
    "            root_dict[p]={}\n",
    "\n",
    "    for publisher in number_publishers:\n",
    "\n",
    "        # referencing inside df\n",
    "        folder_dict = {}\n",
    "        # Filter by publisher\n",
    "        cond_publisher = (df_global['Publisher'] == publisher)\n",
    "        df_by_publisher = df_global[cond_publisher & cond_series].copy()\n",
    "        df_by_publisher.sort_values(by=['Year', 'Month', 'Day'], ascending=[True, True,True], inplace=True, key=natsort_keygen())\n",
    "\n",
    "        # Sorting for smaller publishers\n",
    "        if publisher not in PUBLISHER_LIST:\n",
    "            publisher_path = f\"Misc\\\\{publisher}\"\n",
    "        else:\n",
    "            publisher_path = publisher\n",
    "\n",
    "        # Check Publisher path for pre-existing folders\n",
    "        target_path = f\"D:\\\\-=_Comics_=-\\\\{publisher_path}\\\\\"\n",
    "\n",
    "        DF = DF_Manager(df_by_publisher)\n",
    "        target_folders, two_1_list  = DF.return_target_folders()\n",
    "        # print(target_folders)\n",
    "\n",
    "        # Create new folders and create dictionary reference for Year\n",
    "        for y in target_folders:\n",
    "            if y[0] in (entry for entry in two_1_list):\n",
    "                folder_index = f\"{y[0]}-{y[1]}\"\n",
    "            else:\n",
    "                folder_index = y[0]\n",
    "            folder_dict[folder_index]=[]\n",
    "\n",
    "        #Number of Volumes Check\n",
    "        volumes = df_by_publisher['Volume'].unique()\n",
    "\n",
    "        for volume in volumes:\n",
    "            # Filter by volume\n",
    "            cond_volume = (df_global['Volume'] == volume)\n",
    "            df_by_volume = df_global[cond_volume & cond_publisher & cond_series].copy()\n",
    "            df_by_volume.sort_values(by=['Year', 'Number'], ascending=[True, True], inplace=True, key=natsort_keygen())\n",
    "\n",
    "            years = df_by_volume['Year'].unique()\n",
    "\n",
    "            for year in years:\n",
    "                cond_year = (df_global['Year'] == year)\n",
    "                df_by_year = df_global[cond_year & cond_volume & cond_publisher & cond_series].copy()\n",
    "\n",
    "                # Problem Checker\n",
    "                for row in df_by_year.itertuples():\n",
    "                    try:\n",
    "                        issue_date = dt.datetime(row.Year, row.Month, row.Day)\n",
    "                    except ValueError:\n",
    "                        print(f\"ValueError - {title} {row.Number} - {row.Year}-{row.Month}-{row.Day}\")\n",
    "                        break\n",
    "\n",
    "                    issue_year = row.Year\n",
    "                    issue_month = row.Month\n",
    "                    issue_day = row.Day\n",
    "                    issue_num = row.Number\n",
    "                    save_year = 0\n",
    "                    mod_0 = .85\n",
    "                    pre_issues = (issue_num == 0 or issue_num == 1.5 or issue_num == .5 or issue_num == .1 or issue_num == -1)\n",
    "\n",
    "                    # Sort issues by Year-Month-Day\n",
    "                    for i in range(len(target_folders)):\n",
    "                        # Check for two issue 1 in same year\n",
    "                        if target_folders[i][0] in (entry for entry in two_1_list):\n",
    "                            tf_index = f\"{target_folders[i][0]}-{target_folders[i][1]}\"\n",
    "                            try:\n",
    "                                tf_index_next = f\"{target_folders[i+1][0]}-{target_folders[i+1][1]}\"\n",
    "                            except IndexError:\n",
    "                                tf_index_next = \"0-0\"\n",
    "                        else:\n",
    "                            tf_index = target_folders[i][0]\n",
    "                            try:\n",
    "                                tf_index_next = target_folders[i+1][0]\n",
    "                            except IndexError:\n",
    "                                tf_index_next = 0\n",
    "\n",
    "                        prev_date = dt.datetime(target_folders[i][0], target_folders[i][1], target_folders[i][2])\n",
    "                        if i == len(target_folders)-1:\n",
    "                            if pre_issues and (prev_date - issue_date).days < 365 * mod_0:\n",
    "                                save_year = tf_index\n",
    "                            elif issue_date >= prev_date:\n",
    "                                save_year = tf_index\n",
    "                        else:\n",
    "                            # Standard sort\n",
    "                            next_date = dt.datetime(target_folders[i+1][0], target_folders[i+1][1], target_folders[i+1][2])\n",
    "\n",
    "                            if pre_issues and (next_date - issue_date).days < 365 * mod_0:\n",
    "                                # bumps up save year to the next entry if it's released less than 10 months before issue 1\n",
    "                                save_year = tf_index_next\n",
    "                            elif pre_issues and (prev_date - issue_date).days < 365 * mod_0:\n",
    "                                # bumps up save year to the next entry if it's released less than 10 months before issue 1\n",
    "                                save_year = tf_index\n",
    "                            elif prev_date <= issue_date < next_date:\n",
    "                                save_year = tf_index\n",
    "\n",
    "                    # Add to dictionary\n",
    "                    try:\n",
    "                        folder_dict[save_year].append(issue_num)\n",
    "                    except KeyError:\n",
    "                        print(f\"Key Error - {row.Index} {title} {issue_num} - SaveYear {save_year} : IssueYear {issue_year} - {next_date} - {issue_date}\")\n",
    "                        break\n",
    "\n",
    "                    # Saves the new correct path to df\n",
    "                    move_path = f\"D:\\\\-=_Comics_=-\\\\{publisher_path}\\\\{safe_title} ({save_year})\\\\\"\n",
    "                    df_global.at[row.Index, 'NewPath'] = move_path\n",
    "\n",
    "        title_dict[safe_title].update(folder_dict)\n",
    "        root_dict[publisher].update(title_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95461492",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# for y in root_dict['Marvel']['Chaos War']:\n",
    "#     print(y,' - ', root_dict['Marvel']['Chaos War'][y])\n",
    "\n",
    "# root_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05933545",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c9b9b1d",
   "metadata": {},
   "source": [
    "# CAUTION Permanent - Move Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31c320f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09135bd7daf5434fa5847d11a6e0db15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_preexist = 0\n",
    "count_moved = 0\n",
    "dup_list = []\n",
    "dup_files = []\n",
    "\n",
    "df_move = df_global[df_global.Series.isin(df_import['Series'].unique().tolist())]\n",
    "\n",
    "for row in tqdm(df_move.itertuples()):\n",
    "    move_folder = row.NewPath\n",
    "    _, file_name = os.path.split(row.FilePath)\n",
    "    check_file = move_folder+file_name\n",
    "\n",
    "    if row.FilePath != check_file:\n",
    "        if not os.path.exists(move_folder):\n",
    "            os.makedirs(move_folder)\n",
    "\n",
    "        if os.path.exists(check_file):\n",
    "            # print(f\"Pre-Exists: {move_folder}{file_name} \")\n",
    "            dup_list.append(row.index)\n",
    "            dup_files.append(row.FilePath)\n",
    "            count_preexist+=1\n",
    "        else:\n",
    "            try:\n",
    "                shutil.move(row.FilePath, check_file)\n",
    "                count_moved+=1\n",
    "                df_global.at[row.Index, 'FilePath'] = check_file\n",
    "            except:\n",
    "                print(f'Error: {file_name} - {move_folder}')\n",
    "\n",
    "# not working, error\n",
    "# df_global = df_global.drop(dup_list, axis='index')\n",
    "\n",
    "df_global.to_csv('comic_list.csv')\n",
    "\n",
    "# for f in dup_files:\n",
    "#     os.remove(f)\n",
    "#\n",
    "# print(f\"Total:  {df_move.size} -  Unmoved: {count_preexist}   -   Moved: {count_moved}   -  Duplicates: {len(dup_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f01e2a6-40eb-4fcb-80d9-b5f7b8fd0dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: 0\n"
     ]
    }
   ],
   "source": [
    "# Delete old empty folders\n",
    "\n",
    "end_tree = []\n",
    "count_deleted = 0\n",
    "\n",
    "# Creates a list of all subfolders that are empty\n",
    "for (path, dirs, files) in os.walk(HOME_PATH, topdown=True):\n",
    "    if len(files) == 0 and len(dirs) == 0:\n",
    "        end_tree.append((path, len(dirs)))\n",
    "\n",
    "end_tree= sorted(end_tree, key=lambda x:x[1])\n",
    "\n",
    "for folder in end_tree:\n",
    "    try:\n",
    "        os.rmdir(folder[0])\n",
    "        count_deleted+=1\n",
    "    except:\n",
    "        print(f\"{folder[0]} could not be deleted.\")\n",
    "print(f\"Deleted: {count_deleted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a232efd-2a82-4978-94b5-6b4b212bbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add a check for pre-existing folders that should not be deleted\n",
    "# check for pre-existing folder but missing earlier issues that would lower the year value, copy move delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f2908",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
